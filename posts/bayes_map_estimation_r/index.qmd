---
title: "Bayesian MAP estimation in R"
description: "Understanding the Bayesian idea and reproducing a MAP estimation in R"
author:
  - name: Marian Klose
    url: https://github.com/marianklose
    orcid: 0009-0005-1706-6289
date: 03-29-2025  # MM-DD-YYYY
categories: [NONMEM, Bayes, MAP] 
image: preview.gif
bibliography: C:/Users/maria/Desktop/bibliography.bib
draft: false 
echo: true
execute:
  freeze: false # never re-render during project render (dependencies might change over time)
  echo: true
  message: false
  warning: false
citation: 
  url: https://marian-klose.com/posts/bayes_map_estimation_r/index.html
format:
  html:
    number-sections: true
    toc: true
    code-fold: true
    code-tools: true
---

```{r}
# load packages
library(dplyr)
library(ggplot2)
library(readr)
library(kableExtra)
library(xpose4)
library(tidyr)
```



# Motivation

## Why Bayesian estimation is important

Bayesian estimation is a commonly applied and powerful method in pharmacometrics. Often the calculation happens kind of automatically when we fit a pharmacometric model using e.g., NONMEM. So it is quite easy to use them without dealing the underlying concepts and the actual computation of e.g., the individual parameter estimates provided as an output in NONMEM: Given that diagnostics relying on IPRED (the individual predictions obtained through simulating with the MAP parameter estimate) are commonly reported, and individual parameters are often used for covariate screening, the importance of this topic is clear. The most commonly applied Bayesian tool are so called MAP or EBE estimates, which represent the mode of the posterior distribution (we will talk about the posterior later). However, also the full posterior distribution can be of interest, although it is harder to calculate. In this blogpost, I want to shortly describe my own understanding of the Bayesian ideas and concepts and then show how to reproduce the MAP estimates and its resulting individual predictions (IPRED) in R. An equation-based reproduction is typically the best way to understand and learn about the underlying concept.

## Disclaimer

I just share my personal thoughts and understanding of some Bayesian ideas and I can't promise that you won't find flaws in my explanations or equations. 



# Structure

Lorem ipsum dolor sit amet.

# The Bayesian Idea: Updating Beliefs

## Starting with an example

I would say that most people in their daily life think Bayesian (although not everyone wants to admit it). The core idea of Bayesian statistics is to update your beliefs once new data or information becomes available. One simple example: Assume you commute to work every day by using your car. If someone would ask you "How long do you think you will need to get to work tomorrow?", you would probably have a very good idea about how long it will take you, simply based on your experience. You might say that 30 minutes is a good estimate, but would you bet money that it will be exactly 30 minutes? Most likely not, it might be your best guess but there will be some uncertainly associated to it. You might be willing to bet money that it will be between 20 and 40 minutes. Now assuming that you get into your car the next morning and traffic is a state so that after 25 minutes you made it half-way through.

[IMAGE]

Would you still stick to your initial belief that it will take you 30 minutes? Probably not, you would update your belief. Would you then just multiply the 25 minutes by two and say that it will take you 50 minutes? Probably not, given that all your experience tells you that you nearly always made it within 40 minutes. So your updated belief will be something between 30 minutes (initial guess) and 50 minutes (what the data suggests). This updated belief (let's say 38 minutes) is what Bayesian statistics is all about. And since we apply this Bayesian idea in our daily life, I personally find it quite an intuitive way of thinking statistics. 


## Nomenclature

The real-life example defined above allows us to define some Bayesian nomenclature:

- The **prior** is the initial belief, in our example the 30 minutes and the uncertainty around it.
- The **likelihood** represents the new data (or evidence), in our example the 25 minutes for 1/2 of the way.
- The **posterior** is the updated belief after the data became available, in our example the 38 minutes.

So the Bayesian workflow is always based on the idea that you have a prior belief, which you update once new data (likelihood) becomes available. The updated belief is then called the posterior. There are some differences if we talk about MAP estimation and full posterior estimation:

- MAP: the *maximum a-posteriori* estimate, which is the mode of the posterior distribution
- full Bayesian: the full posterior distribution and not only the mode / a point estimate

Most pharmacometricians focus on the mode of the posterior (MAP/EBE) and neglect the uncertainty captured in the full distribution. The main reason for this is that the MAP estimates are easy to calculate while the full posterior is more challenging to obtain.

It goes without a saying that this is a simple example and everything is just based on a gut-feeling than on equations. While the core-idea remains the same, Bayesian statistics provide a framework to calculate the posterior in a more formal way. This is what we are tackling next.


## Our goal in pharmacometrics

But what is now the goal of Bayesian stats in pharmacometrics? Actually not to better plan your daily commute to work. Instead, we typically use Bayesian estimation to individualize the model parameters for a given individual $i$, which has a set of observations $Y_{i}$. Now we want to use this individual data to find the best parameter estimates for this individual. On the one hand this happens during model building, at each iteration step and then after the actual estimation has finished, at the posthoc step. On the other hand, it also happens in so called model-informed precision dosing scenarios (MIPD) where we want to predict the future concentration-time profile and we have obtained some historic concentrations through therapeutic drug monitoring. 


# Pharmacokinetic example and reference solution

## Data

Without data no Bayesian parameter individualization. As we do this MAP estimation on an individual level, we are going to pick one single ID from the dataset we have defined in the previous blogpost [REF]and use this as as our example. Let's first load the simulated concentration-time data and show the head of it:

```{r}
# read in simulated dataset from previous blogpost
sim_data <- read_csv("~/GitHub/personal-website/posts/understanding_nlme_estimation/data/output_from_sim/sim_data.csv")

# show data 
sim_data |>  
  head() |> 
  kable() |> 
  kable_styling()
```

These is the previously simulated data with which we have built the model. We will focus on one single ID (ID 5) which is rather at the lower end of the simulated concentrations. We did this as it allows us to better see the differences between the typical individual and the individualized one. Let's plot the data to get a better understanding of the concentration-time profiles:


```{r}
#| label: fig-sim-vis
#| fig-cap: "Simulated concentration-time profiles for 10 individuals with ID 5 being our examplaratory ID."

# show individual profiles
sim_data |> 
  filter(EVID == 0) |> 
  mutate(flag = if_else(ID == 5, "Reference", "Others")) |>
  ggplot(aes(x=TIME, y=DV, group=ID, color=as.factor(flag))) +
  geom_point()+
  geom_line()+
  theme_bw()+
  scale_y_continuous(limits=c(0,NA))+
  labs(x="Time after last dose [h]", y="Concentration [mg/L]")+
  scale_color_manual("Individual", values=c("grey", "darkblue"))+
  ggtitle("Simulated data")
```

We will later need this data when running NONMEM, so we have to save it to file. 

```{r}
# define sim_data with ID == 5
sim_data_id5 <- sim_data |> 
  filter(ID == 5)

# save data for NONMEM
sim_data_id5 |> 
  write_csv("~/GitHub/personal-website/posts/bayes_map_estimation_r/data/sim_data_ID5.csv") 
```


## NLME model structure

For a little example and the reference solution, we will use the same simple one-compartment i.v. model with first order disposition processes we have fitted to some data here [REF]. This was the model structure:

![Model structure of our simple 1 cmt i.v. bolus model.](media/model_structure.png)

We assume to have an already fitted model and our only task is to individualize the parameters for our given individual. The model parameter estimates which we are using are mainly taken from the previous blogpost [REF]:

- $CL$ = 0.247 L/h
- $V$ = 3.15 L
- $\omega^2_{CL}$ = 0.11
- $\sigma^2_{RUV\_ADD}$ = 0.10
- $\sigma^2_{RUV\_PROP}$ = 0.10

This is what we are now going to translate into a NONMEM model. Please note that we added a proportional error term to the previously used model to better make a point when comparing prior, likelihood and posterior. 

## NONMEM model

The NONMEM model is based on the previous blogpost, but we have made some minor edits:

```{.r filename="1cmt_iv_map_est.mod"}
$PROBLEM 1cmt_iv_map_est

$INPUT ID TIME EVID AMT RATE DV MDV

$DATA C:\Users\maria\Documents\GitHub\personal-website\posts\bayes_map_estimation_r\data\sim_data_ID5.csv IGNORE=@

$SUBROUTINES ADVAN1 TRANS2

$PK
; define fixed effects parameters
CL = THETA(1) * EXP(ETA(1))
V = THETA(2)

; scaling
S1=V

$THETA
0.247 FIX               ; 1 TVCL
3.15 FIX                ; 2 TVV

$OMEGA 
0.11 FIX                ; 1 OM_CL

$SIGMA
0.10 FIX                ; 1 SIG_PROP
0.10 FIX                ; 2 SIG_ADD

$ERROR 
; add residual unexplained variability
IPRED = F
Y = IPRED + IPRED * EPS(1) + EPS(2)

$ESTIMATION METHOD=COND LAPLACIAN MAXEVAL=0 SIGDIG=3 PRINT=1 NOABORT POSTHOC

$TABLE ID TIME EVID AMT RATE DV PRED IPRED MDV ETA1 CL NOAPPEND ONEHEADER NOPRINT FILE=map_estim_out
```


We have updated the initial parameter estimates to the estimates listed above. Furthermore, we run with `MAXEVAL=0` as we don't need a full estimation but only a MAP estimation. The `POSTHOC` option will force NONMEM to calculate the individual MAP estimates. We can now go ahead and run it.

After executing the model, we can read in `map_estim_out`:

```{r}
# load simulated data
nm_out <- read_nm_table("~/GitHub/personal-website/posts/bayes_map_estimation_r/models/map_estim_out")

# show simulated data
nm_out |> 
  head() |> 
  kable() |> 
  kable_styling()
```


`ETA1` (or $\eta_i$) is the individual random effect for the individual and `CL` (better $CL_i$) represents the resulting individual MAP estimate for the clearance. `CL_i` can be obtained by

$$CL_i = \theta_{TVCL} \cdot \exp(\eta_i)$$

We can confirm this by calculating:

$$CL_i = 0.247 \cdot \exp(0.4763) = 0.3977$$

or directly in R:

```{r}
#| code-fold: FALSE

# calculate individual MAP estimate
0.247*exp(0.4763)
```

Great! Now we have our reference solution for the parameter individualization. We not only got the individualized parameter estimates but also the individual predictions (`IPRED`). We can now compare both visually:

```{r}
# plot DV, PRED, IPRED
nm_out |> 
  filter(TIME > 0) |> 
  pivot_longer(cols=c(PRED, IPRED, DV), names_to="variable", values_to="value") |>
  ggplot(aes(x=TIME, y=value, group=variable, color=variable))+
  geom_point()+
  geom_line()+
  labs(
    y = "Concentration [mg/L]",
    x = "Time after last dose [h]",
    title = "Comparison of DV, PRED and IPRED"
  ) +
  theme_bw() 
```

We can see at a first glance that our reference individual (red, `DV`) differs substantially from our typical individual (blue, `PRED`). The individual predictions (green, `IPRED`), which are based on our MAP estimate for CL (`CL_i`), are in between. Let's have a closer look how to get there.


## Bayesian Theory

### General form

As described above, the main goal of a Bayesian attempt is to obtain the posterior distribution (either the mode or the full distribution). Often you find this formula to describe the Bayes theorem: 

$$P(A|B) = \frac{P(A) \cdot P(B|A)}{P(B)}$$

Here, conditional probabilities are used and $P(A|B)$ is the probability of event A given that event B has occurred. This remains quite theoretical. Let's directly translate it into the context of a pharmacokinetic NLME model. 

### Pharmacometric context

Our use-case in the world of pharmacometrics is to find the most likely parameter $\eta_i$ (which then translates to $CL_i$) given our individual's concentration data $Y_{i}$:

$$p(\eta|Y_{i}) = \frac{p(\eta) \cdot p(Y_{i}|\eta)}{p(Y_i)}$$

with 

- $p(\eta|Y_{ij})$: the posterior distribution of the parameter $\eta$ given the data of our ith individual $Y_{i}$
- $p(\eta)$: the prior distribution of the parameter $\eta$
- $p(Y_{i}|\eta)$: the likelihood of the data $Y_{i}$ given the parameter $\eta$
- $p(Y_{i})$: the marginal likelihood of the data $Y_{i}$

The marginal likelihood of the data $Y_{i}$ is often neglected since it is just a scaling factor, does not depend on the parameter $\eta$ and is typically hard to calculate as it contains a high-dimensional integral. That is why you often see the formula written as:

$$p(\eta|Y_{i}) \propto p(\eta) \cdot p(Y_{i}|\eta)$$

Here, we got rid of the marginal likelihood in the denominator. As we are now missing out the scaling factor, we now deal with an unnormalized posterior distribution and indicate this by using the proportional sign. Dealing with unnormalized posteriors is not a problem if we are only interested in the mode of the posterior distribution (MAP estimate) as the normalization factor is not needed for this. But how can we calculate the MAP estimate for a given individual? 


### MAP estimation

If we are interested to find the most likely parameter for our individual, we have to find the maximum of the posterior distribution (MAP estimate). Mathematically we can define this by finding the parameter $\eta_i^*$ that maximizes the posterior distribution:

$$\eta_i^* = \underset{\eta_i}{\mathrm{argmax}}~ p(\eta_i|Y_{i}) = \underset{\eta_i}{\mathrm{argmax}}~ p(\eta_i) \cdot \prod_{j=1}^{m} p(Y_{ij}|\eta_i)$$

Dealing with the product of probabilities is often not very handy and we can simplify this by taking the log of the posterior distribution:

$$\eta_i^* = \underset{\eta_i}{\mathrm{argmax}}~ \log(p(\eta_i|Y_{i})) = \underset{\eta_i}{\mathrm{argmax}}~ \log(p(\eta_i)) + \sum_{j=1}^{m} \log(p(Y_{ij}|\eta_i))$$

In the end, we would have to use a numerical optimizer function to search the parameter space of $\eta_i$ to find the maximum of the posterior distribution ($\eta_i^*$). To write out the full equation we need to define both terms, $p(\eta_i)$ and $p(Y_{ij}|\eta_i)$. Let's go through them step by step.

#### Prior term

The prior distribution for $p(\eta_i)$ needs to incorporate our beliefs and uncertainty about $\eta_i$ before we have seen the data. Bayesian estimation actually allows us to incorporate our prior information through different distributions and parameters (which is sometimes being criticized being too subjective). In pharmacometrics, you will often see that people use the same distribution based on a previously estimates model. This is usually a normal distribution with mean 0 and a variance $\omega^2_{CL}$ estimated by the NLME model. What is the intuition behind this? When searching the space of $\eta_i$ during $\underset{\eta_i}{\mathrm{argmax}}$, we need to evaluate at each point how likely the given $\eta_i$ is given the prior distribution. This means that individual random effects at the boundaries of the prior distribution are discouraged while those in the center are encouraged. Or in other words: We only want to move away from the typical individual estimate when we get a substantial gain in explaining the data. To calculate the contribution of the prior term, we rely on the probability density function of the normal distribution:
 

$$p(\eta_i) = \frac{1}{\sqrt{2\pi\omega^2}} \cdot \exp\left(-\frac{(\eta_i-\mu)^2}{2\omega^2}\right)$$

As $\mu$ is typically 0, we can simplify this to:

$$p(\eta_i) = \frac{1}{\sqrt{2\pi\omega^2}} \cdot \exp\left(-\frac{\eta_i^2}{2\omega^2}\right)$$

Taking the log yields:

$$\log(p(\eta_i)) = -0.5 \log(2\pi\omega^2) - \frac{\eta_i^2}{2\omega^2} $$


Now we are able to calculate the contribution of the prior term for a given individual $\eta_i$, as we know the variance $\omega^2_{CL}$ (0.11) from our NLME model.

#### Likelihood term

The likelihood term $p(Y_{ij}|\eta_i)$ is the probability of observing the data point $Y_{ij}$ given the parameter $\eta_i$. As we usually also assume that the residuals of our model predictions are normally distributed, we can also use the probability density function of the normal distribution to calculate this term. The likelihood term is then:

$$p(Y_{ij}|\eta_i) = \frac{1}{\sqrt{2\pi\sigma^2}} \cdot \exp\left(-\frac{(Y_{ij}-f(x_{ij}; \eta_i))^2}{2\sigma^2}\right)$$
where

- $Y_{ij}$ is the observed data point of the individual $i$ at time $j$
- $f(x_{ij}; \eta_i)$ is the model prediction for the individual $i$ at time $j$ given the individual random effect $\eta_i$ (for CL)
- $\sigma^2$ is the variance of the residual unexplained variability of the model

Please note that in our case, where we have a combined additive and proportional RUV model, $\sigma^2$ is the sum of both variances at time $j$. We can take the log and get:

$$\log(p(Y_{ij}|\eta_i)) = -0.5 \log(2\pi\sigma^2) - \frac{(Y_{ij}-f(x_{ij}; \eta_i))^2}{2\sigma^2}$$

### Combining both terms

Now we can combine both terms:

$$\eta_i^* = \underset{\eta_i}{\mathrm{argmax}}~\left(\left[-0.5 \log(2\pi\omega^2) - \frac{\eta_i^2}{2\omega^2}\right] ~ + \left[-0.5 \log(2\pi\sigma^2) - \frac{(Y_{ij}-f(x_{ij}; \eta_i))^2}{2\sigma^2}\right]\right)$$

This is the equation for which our numerical optimizer needs to find the maximum (or minimum if negated) to obtain the individual MAP estimate. Let's define some functions and reproduce our NONMEM reference solution in R.


# R-based MAP reproduction

## Prior term

We will start to define a function with the prior term

```{r filename="function: prior_fun()"}
#| echo: true
#| collapse: false
#| code-fold: false

# define prior term function
prior_fun <- function(eta_i, omega2){
  # calculate probability
  log_prob <- - 0.5 * log(2*pi*omega2) - eta_i^2/(2*omega2)
  
  # return log probability
  return(log_prob)
}
```

We can now test this function and illustrate the prior term for a range of $\eta_i$ values:

```{r}
# define range
eta_i <- seq(-2, 2, 0.01)

# calculate prior term
prior <- prior_fun(eta_i = eta_i, omega2 = 0.11)

# create tibble
prior_tibble <- tibble(
  eta_i = eta_i,
  exp_prior = exp(prior),
  source = "prior"
)

# plot prior term
prior_tibble |> 
  ggplot(aes(x=eta_i, y=exp_prior))+
  geom_line()+
  labs(
    x = expression(eta[i]),
    y = expression(p(eta[i])),
    title = "Prior term (Random effect)"
  )+
  theme_bw()
```


and this is how the $\eta_i$ values translate to the Clearance domain:

```{r}
# plot prior term
prior_tibble |> 
  ggplot(aes(x=0.247*exp(eta_i), y=exp_prior))+
  geom_line()+
  labs(
    x = expression(CL[i]),
    y = expression(p(CL[i])),
    title = "Prior term (Clearance)"
  )+
  theme_bw()
```


We can see that some values of $\eta_i$ and $CL_i$ are more likely than others. Based on the results of the fitted NLME model, these distributions represent our prior beliefs before we see the data of the given individual.


## Likelihood term

For the Likelihood term described in [IREF] we need to define the model prediction function. The simple 1 cmt model structure we are using allows us to use a closed-form expression of the model instead of relying on ODE-based numerical solutions (see [REF]). But the concepts remain the same and you could apply this also if you have an ODE-based system. Let's first define the model prediction function:

```{r filename="function: model_fun()"}
#| echo: true
#| collapse: false
#| code-fold: false

# define model function
model_fun <- function(eta_i, dose, vd, theta_tvcl, t) {
  exp_eta_i <- exp(eta_i)
  exponent <- -1 * (theta_tvcl * exp_eta_i / vd) * t
  result <- (dose / vd) * exp(exponent)
  return(result)
}
```

We can now use the prediction function and build the likelihood term function:

```{r filename="function: likelihood_fun()"}
#| echo: true
#| collapse: false
#| code-fold: false

# define likelihood term function
likelihood_fun <- function(eta_i, dose, vd, theta_tvcl, t, Y_i, sigma2_add, sigma2_prop){
  
  # get model predictions
  f_i <- model_fun(eta_i, dose, vd, theta_tvcl, t)
  
  # calculate resulting sigma2 for each timepoint (prop variance is scaled based on f_i^2)
  sigma2 <- sigma2_prop * f_i^2 + sigma2_add
  
  # calculate probability
  log_lik <- - 0.5 * log(2*pi*sigma2) - (Y_i - f_i)^2/(2*sigma2)
  
  # take sum of likelihoods
  log_lik_sum <- sum(log_lik)
  
  # return log likelihood
  return(log_lik_sum)
}
```

 We can now test this function and illustrate the likelihood term for a range of $\eta_i$ values:

```{r}
# define range
eta_i <- seq(-2, 2, 0.01)

# empty list
ll_list <- list()

# loop over each element of eta_i
for(cur_eta_i in eta_i){
  # calculate likelihood term
  ll_list[[as.character(cur_eta_i)]] <- likelihood_fun(
    eta_i = cur_eta_i, 
    dose = nm_out |> filter(EVID == 1) |> pull(AMT), 
    vd = 3.15, 
    theta_tvcl = 0.247, 
    t = nm_out |> filter(EVID == 0) |> pull(TIME), 
    Y_i = nm_out |> filter(EVID == 0) |> pull(DV), 
    sigma2_add = 0.10, 
    sigma2_prop = 0.10
  )
}

# convert to vector
ll_vector <- ll_list |> unlist() |> unname()

# create tibble
likelihood_tibble <- tibble(
  eta_i = eta_i,
  likelihood = ll_vector,
  source = "likelihood"
)

# plot likelihood term
likelihood_tibble |> 
  ggplot(aes(x=eta_i, y=exp(likelihood)))+
  geom_line()+
  labs(
    x = expression(eta[i]),
    y = expression(p(Y[i] | eta[i])),
    title = "Likelihood term"
  )+
  theme_bw()
```

Here we can see which values of $\eta_i$ are more and less likely to describe the observed data $Y_i$ of our example individual. Now we can go ahead and combine both terms to calculate the MAP estimate for our individual.

## MAP estimation

We now have to define an objective function for the numerical optimizer which will maximize the posterior distribution as defined in [IREF]. We simply have to put together both terms:


```{r filename="function: map_obj_fun()"}
#| echo: true
#| collapse: false
#| code-fold: false

# define MAP estimation objective function
map_obj_fun <- function(eta_i, omega2, dose, vd, theta_tvcl, t, Y_i, sigma2_add, sigma2_prop){
  
  # calculate log prior term
  log_prior_term <- prior_fun(
    eta_i = eta_i, 
    omega2 = omega2
  )
  
  # calculate log likelihood term
  log_likelihood_term <- likelihood_fun(
    eta_i = eta_i, 
    dose = dose, 
    vd = vd, 
    theta_tvcl = theta_tvcl, 
    t = t, 
    Y_i = Y_i, 
    sigma2_add = sigma2_add, 
    sigma2_prop = sigma2_prop
  )
  
  # combine both
  log_posterior <- log_prior_term + log_likelihood_term
  
  # return negative log posterior
  return(-log_posterior)
}


```


Please note that we are returning the negative log posterior as it is easier to minimize a function than to maximize it. We can now use this objective function to find the MAP estimate for our individual using the `optim` function in R. We want to find the particular value of $\eta_i$ which minimizes our `map_obj_fun()` function. 

```{r}
# run optimization
map_est <- optim(
  par = 0, 
  fn = map_obj_fun, 
  omega2 = 0.11, 
  dose = nm_out |> filter(EVID == 1) |> pull(AMT), 
  vd = 3.15, 
  theta_tvcl = 0.247, 
  t = nm_out |> filter(EVID == 0) |> pull(TIME), 
  Y_i = nm_out |> filter(EVID == 0) |> pull(DV), 
  sigma2_add = 0.10, 
  sigma2_prop = 0.10,
  method = "BFGS"
)

# show estimation results
map_est 
```




# Conclusion

- Summarize benefits of performing Bayesian estimation explicitly.

- Encourage pharmacometricians to reproduce standard software results occasionally to enhance intuition.

# Epilogue / Acknowledgments

- xxx


