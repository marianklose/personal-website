{
  "hash": "30f67015d2f81a599bffbf4d900d007b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using ChatGPT with Python\"\ndescription: \"Supercharging ChatGPT by accessing it from the command line.\"\nauthor:\n  - name: Marian Klose\n    url: https://github.com/marianklose\n    orcid: 0009-0005-1706-6289\ndate: 01-12-2025\ncategories: [ChatGPT, openai, LLM] \nimage: preview.png\nbibliography: C:/Users/mklose/Desktop/bibliography.bib\ndraft: true\ndraft-mode: \"gone\"\necho: true\nexecute:\n  freeze: true # never re-render during project render (dependencies might change over time)\n  echo: true\n  message: false\n  warning: false\ncitation: \n  url: https://marian-klose.com/posts/command_line_chatgpt/index.html\nformat:\n  html:\n    number-sections: false\n    toc: true\n    code-fold: true\n    code-tools: true\n---\n\n\n\n# Prologue\n\n## Motivation\n\n## Why python\n\n- Openai provides packages (or so called Software Development Kits, SDKs) to interact with their API (Application Programming Interface) for different programming languages such as JavaScript and Python. \n- However, you can also directly interact with openais API using raw HTTP requests. This allows you to use ChatGPT also in programming languages for which no offical packages / SDKs exist, such as R. \n- Although I am more profound in R, I have anyways chosen to use python since I am already somewhat familiar with it through prior projects, and I personally prefer the convenience to have a pre-built package instead of dealing with raw HTTP requests.\n\n# Setup\n\n- For the setup, we will basically follow the quickstart guidance from openai for developers: https://platform.openai.com/docs/quickstart?language-preference=python\n\n## Creating an account\n\n- when we want to access ChatGPT from the command line, we need to have an openai account\n- We can simply go to https://platform.openai.com/signup and create ourselves an account\n\n## Retrieve your API key\n\n- API keys are long, random strings used to authenticate and authorize access to an API. You can view it as a password (and it should also be handled as such). Since you pay money per prompt you send (even if it is a small amount), you don't want to hand your password to a random person in the internet.\n- You can generate youreself an API key via https://platform.openai.com/api-keys once you have your account.\n\nxxxSCREENSHOTxxx\n\n- From the Screenshot you can see that I have a API key for my laptop starting with *sk-....YLUA*. \n\n## Saving your API key as an environmental variable\n\n- We want to avoid to always type in this key or to save it in a script, since this would be similar to hard coding your password somewhere. Everyone who can see this script would also have you API key / password. \n- One common way is to save the API key as an environmental variable on your windows machine. You can do so by searching \"System environment variables\" using the windows search function.\n- An alternative way would be to use PowerShell (so basically the command line in Windows) to set your environment variable\n\n\n\n::: {.cell filename='powershell'}\n\n```{.r .cell-code  code-fold=\"false\"}\nsetx OPENAI_API_KEY \"your_api_key_here\"\n```\n:::\n\n\n\n- Make sure to name your environmental variable exactly like this \"OPENAI_API_KEY\". The `openai` package in python looks for this specific name once you initialize it.\n- Great! Now we have our API key / password ready to use it in python.\n\n## Setting up Pyhton\n\n- I don't really want to go into the details how to set up python itself (there are enough great tutorials out there)\n- To install the openai package we would simply use the package installer for python, pip:\n\n\n\n\n::: {.cell filename='powershell'}\n\n```{.r .cell-code  code-fold=\"false\"}\npip install python\n```\n:::\n\n\n\n- With that we have now successfully installed the openai package to interact with the openai API and we also have our API key ready to be used as an environmental variable. We can now go on to have our first prompt.\n\n\n## Our first prompt\n\n- Sending an request to chatgpt is rather simple. Let's have a look at the code\n- First, we are going to load our packages and initialize the openai client\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code  code-fold=\"false\"}\n# load packages\nfrom openai import OpenAI\nimport json\n\n# initialize openai client\nclient = OpenAI()\n```\n:::\n\n\n\n- Now we can already send the prompt to chatgpt. We are using the `gpt-4o` model for this, but there are many other models available. The available models should be available here: https://platform.openai.com/docs/models\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code  code-fold=\"false\"}\n# send request\ncompletion = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\n          \"role\": \"system\",\n          \"content\": \"You are a comedian with a PhD in pharmacometrics.\"\n        },\n        {\n          \"role\": \"user\",\n          \"content\": \"Write a short joke about pharmacokinetics.\"\n        }\n    ]\n)\n```\n:::\n\n\n\n- Please note that we need to provide input for at least two roles: The *user* role ist more familiar to us as this is the actual prompt we are typically sending when using the webinterface of ChatGPT. Now we also provide input for the *sytem* role. The *system* role in ChatGPT defines the model's behavior, tone, and response style, guiding how it interacts with users. So we actually get some more degrees of freedom here and can already centrally define the general model behaviour. \n- Let's see what the completion object is all about:\n\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code  code-fold=\"false\"}\n# print full object\nprint(completion)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nChatCompletion(id='chatcmpl-B9pyYgrxghgGi5Qr3RtA9dXKlPsyP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Why did the drug go to therapy? \\n\\nBecause it had first-pass issues and couldn't get past its metabolism!\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1741684446, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_f9f4fb6dbf', usage=CompletionUsage(completion_tokens=23, prompt_tokens=34, total_tokens=57, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n```\n\n\n:::\n:::\n\n\n\n- In many cases we are only interested in accessing the actual message, so we can retrieve this by writing:\n\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code  code-fold=\"false\"}\n# print object\nprint(completion.choices[0].message.content)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWhy did the drug go to therapy? \n\nBecause it had first-pass issues and couldn't get past its metabolism!\n```\n\n\n:::\n:::\n\n\n\n- Now we have successfully written our first prompt!\n\n\n\n# Use-Cases\n\n## Repetition\n\n## Scheduled content\n\n## Text revision\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}